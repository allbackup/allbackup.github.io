<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"   "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>tokenize</title>
<style type='text/css'>body { font: 100% Georgia, Times, serif; } a.nav:link, a.nav:visited { color: #88f; } .nav { color: #88f; } a.nav:hover { color: blue; } .mark { color: #048444; }</style>
<meta http-equiv='Content-Type' content='text/html;charset=utf-8' />
</head><body>
<table style='font-size: 8pt; background: #efe; padding: 5px; border: 1px solid #084; margin: 0px 0px 20px 0px;' border='0' cellspacing='0' cellpadding='0' width='100%'><tr><td align='left'>
an alternative python reference (<a href='/zone/pythondoc-lib.htm'>in progress</a>)
</td><td align='right'>
<a href='http://docs.python.org/lib/module-tokenize.html'>original</a> :::
<a href='tokenize.txt'>source</a> :::
<a href='/lib/index.html'>index</a>
</td></tr></table><table style='font-size: 8pt; background: white; padding: 5px; border: 1px solid #084; margin: 0px 0px 20px 0px;' border='0' cellspacing='0' cellpadding='0' width='100%%'><tr><td align='left'>
<b>note:</b> this page has been automatically converted from python.org
sources, and may contain errors and omissions introduced by the conversion
process.
</td></tr></table><div class="body"><div class="module">
<h1>tokenize&#8212;Tokenizer for Python source</h1>

<p>The <a class="link" href="#tokenize"><code>tokenize</code></a> module
provides a lexical scanner for Python source code, implemented in
Python. The scanner in this module returns comments as tokens as
well, making it useful for implementing
&#8220;pretty-printers,&#8221; including colorizers for on-screen
displays.</p>

<p>The primary entry point is a generator:</p>
</div>
<dl><dt class="function" id="generate_tokens"><b>generate_tokens(readline)</b> <tt class="nav"><a class="nav" href="tokenize.generate_tokens" title="bookmark">#</a>|<a class="nav" href="#" title="edit/suggest changes">!</a>|<a class="nav" href="#" title="search for related examples">&amp;</a></tt></dt>

<dd class="function">
<p>The <a class="link" href="#generate_tokens"><code>
generate_tokens</code></a> generator requires one argment, <var>
readline</var>, which must be a callable object which provides the
same interface as the <code>
readline</code> method of built-in file objects (see section <code>
bltin-file-objects.html#bltin-file-objects</code>). Each call to the
function should return one line of input as a string.</p>

<p>The generator produces 5-tuples with these members: the token
type; the token string; a 2-tuple <code>(</code><var>srow</var>,
<var>scol</var>) of ints specifying the row and column where the
token begins in the source; a 2-tuple <code>
(</code><var>erow</var>, <var>ecol</var>) of ints specifying the
row and column where the token ends in the source; and the line on
which the token was found. The line passed is the <em>logical</em>
line; continuation lines are included.</p>

<blockquote><span class="mark">@since</span> New in version
2.2.<br />
</blockquote>
</dd>
</dl><div class="text">
<p>An older entry point is retained for backward compatibility:</p>
</div>
<dl><dt class="function" id="tokenize"><b>tokenize(readline[, tokeneater])</b> <tt class="nav"><a class="nav" href="tokenize.tokenize" title="bookmark">#</a>|<a class="nav" href="#" title="edit/suggest changes">!</a>|<a class="nav" href="#" title="search for related examples">&amp;</a></tt></dt>

<dd class="function">
<p>The <a class="link" href="#tokenize"><code>tokenize</code></a> function
accepts two parameters: one representing the input stream, and one
providing an output mechanism for <a class="link" href="#tokenize"><code>tokenize</code></a>.</p>

<p>The first parameter, <var>readline</var>, must be a callable
object which provides the same interface as the <code>readline</code> method of built-in file objects
(see section <code>
bltin-file-objects.html#bltin-file-objects</code>). Each call to the
function should return one line of input as a string.</p>

<p>The second parameter, <var>tokeneater</var>, must also be a
callable object. It is called once for each token, with five
arguments, corresponding to the tuples generated by <a class="link" href="#generate_tokens"><code>generate_tokens</code></a>.</p>
</dd>
</dl><div class="text">
<p>All constants from the <code>
token</code> module are also exported from <a class="link" href="#tokenize"><code>tokenize</code></a>, as are two additional token type
values that might be passed to the <var>tokeneater</var> function
by <a class="link" href="#tokenize"><code>tokenize</code></a>:</p>
</div>
<dl><dt class="variable" id="COMMENT"><b>COMMENT</b> <tt class="nav"><a class="nav" href="tokenize.COMMENT" title="bookmark">#</a>|<a class="nav" href="#" title="edit/suggest changes">!</a>|<a class="nav" href="#" title="search for related examples">&amp;</a></tt></dt>

<dd class="variable">
<p>Token value used to indicate a comment.</p>
</dd>
<dt class="variable" id="NL"><b>NL</b> <tt class="nav"><a class="nav" href="tokenize.NL" title="bookmark">#</a>|<a class="nav" href="#" title="edit/suggest changes">!</a>|<a class="nav" href="#" title="search for related examples">&amp;</a></tt></dt>

<dd class="variable">
<p>Token value used to indicate a non-terminating newline. The
NEWLINE token indicates the end of a logical line of Python code;
NL tokens are generated when a logical line of code is continued
over multiple physical lines.</p>
</dd>
</dl></div></body></html>
