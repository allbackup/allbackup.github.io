
@@module urllib

<h1>urllib&#8212;Open arbitrary resources by URL</h1>

<p>This module provides a high-level interface for fetching data across
the World Wide Web. In particular, the {@link urlopen} function is
similar to the built-in function {@link open}, but accepts Universal
Resource Locators (URLs) instead of filenames. Some restrictions apply
-- it can only open URLs for reading, and no seek operations are
available.

<p>It defines the following public functions:

@@function urlopen(url[, data[, proxies]])

<p>Open a network object denoted by a URL for reading. If the URL does
not have a scheme identifier, or if it has file: as its scheme
identifier, this opens a local file (without universal newlines);
otherwise it opens a socket to a server somewhere on the network. If the
connection cannot be made, or if the server returns an error code, the
{@link exceptions.IOError} exception is raised. If all went well, a
file-like object is returned. This supports the following methods:
{@link read}, {@link readline}, {@link readlines}, {@link fileno},
{@link close}, {@link info} and {@link geturl}. It also has proper
support for the iterator protocol. One caveat: the {@link read} method,
if the size argument is omitted or negative, may not read until the end
of the data stream; there is no good way to determine that the entire
stream from a socket has been read in the general case.

<p>Except for the {@link info} and {@link geturl} methods, these methods
have the same interface as for file objects -- see section {@link
bltin-file-objects.html#bltin-file-objects} in this manual. (It is not a
built-in file object, however, so it can't be used at those few places
where a true built-in file object is required.)

<p>The {@link info} method returns an instance of the class {@link
mimetools.Message} containing meta-information associated with the URL.
When the method is HTTP, these headers are those returned by the server
at the head of the retrieved HTML page (including Content-Length and
Content-Type). When the method is FTP, a Content-Length header will be
present if (as is now usual) the server passed back a file length in
response to the FTP retrieval request. A Content-Type header will be
present if the MIME type can be guessed. When the method is local-file,
returned headers will include a Date representing the file's
last-modified time, a Content-Length giving file size, and a
Content-Type containing a guess at the file's type. See also the
description of the {@link mimetools} module.

<p>The {@link geturl} method returns the real URL of the page. In some
cases, the HTTP server redirects a client to another URL. The {@link
urlopen} function handles this transparently, but in some cases the
caller needs to know which URL the client was redirected to. The {@link
geturl} method can be used to get at this redirected URL.

<p>If the {@var url} uses the http: scheme identifier, the optional
{@var data} argument may be given to specify a {@code POST} request
(normally the request type is {@code GET}). The {@var data} argument
must be in standard application/x-www-form-urlencoded format; see the
{@link urlencode} function below.

<p>The {@link urlopen} function works transparently with proxies which
do not require authentication. In a Unix or Windows environment, set the
http_proxy, ftp_proxy or gopher_proxy environment variables to a URL
that identifies the proxy server before starting the Python interpreter.
For example (the "{@code %}" is the command prompt):

<pre>
% http_proxy="http://www.someproxy.com:3128"
% export http_proxy
% python
...
</pre>


<p>In a Windows environment, if no proxy environment variables are set,
proxy settings are obtained from the registry's Internet Settings
section.

<p>In a Macintosh environment, {@link urlopen} will retrieve proxy
information from Internet Config.

<p>Alternatively, the optional {@var proxies} argument may be used to
explicitly specify proxies. It must be a dictionary mapping scheme names
to proxy URLs, where an empty dictionary causes no proxies to be used,
and {@link None} (the default value) causes environmental proxy settings
to be used as discussed above. For example:

<pre>
# Use http://www.someproxy.com:3128 for http proxying
proxies = {'http': 'http://www.someproxy.com:3128'}
filehandle = urllib.urlopen(some_url, proxies=proxies)
# Don't use any proxies
filehandle = urllib.urlopen(some_url, proxies={})
# Use proxies from environment - both versions are equivalent
filehandle = urllib.urlopen(some_url, proxies=None)
filehandle = urllib.urlopen(some_url)
</pre>


<p>The {@link urlopen} function does not support explicit proxy
specification. If you need to override environmental proxy settings, use
{@link URLopener}, or a subclass such as {@link FancyURLopener}.

<p>Proxies which require authentication for use are not currently
supported; this is considered an implementation limitation.
<blockquote>
@since Changed in version 2.3: Added the
proxies support. <br />
</blockquote>

@@function urlretrieve(url[, filename[, reporthook[, data]]])

<p>Copy a network object denoted by a URL to a local file, if necessary.
If the URL points to a local file, or a valid cached copy of the object
exists, the object is not copied. Return a tuple {@code (}{@var
filename}, {@var headers}) where {@var filename} is the local file name
under which the object can be found, and {@var headers} is whatever the
{@link info} method of the object returned by {@link urlopen} returned
(for a remote object, possibly cached). Exceptions are the same as for
{@link urlopen}.

<p>The second argument, if present, specifies the file location to copy
to (if absent, the location will be a tempfile with a generated name).
The third argument, if present, is a hook function that will be called
once on establishment of the network connection and once after each
block read thereafter. The hook will be passed three arguments; a count
of blocks transferred so far, a block size in bytes, and the total size
of the file. The third argument may be {@code -1} on older FTP servers
which do not return a file size in response to a retrieval request.

<p>If the {@var url} uses the http: scheme identifier, the optional
{@var data} argument may be given to specify a {@code POST} request
(normally the request type is {@code GET}). The {@var data} argument
must in standard application/x-www-form-urlencoded format; see the
{@link urlencode} function below.

@@variable _urlopener

<p>The public functions {@link urlopen} and {@link urlretrieve} create
an instance of the {@link FancyURLopener} class and use it to perform
their requested actions. To override this functionality, programmers can
create a subclass of {@link URLopener} or {@link FancyURLopener}, then
assign an instance of that class to the {@code urllib._urlopener}
variable before calling the desired function. For example, applications
may want to specify a different User-Agent: header than {@link
URLopener} defines. This can be accomplished with the following code:

<pre>
import urllib

class AppURLopener(urllib.FancyURLopener):
    version = "App/1.7"

urllib._urlopener = AppURLopener()
</pre>


@@function urlcleanup()

<p>Clear the cache that may have been built up by previous calls to
{@link urlretrieve}.

@@function quote(string[, safe])

<p>Replace special characters in {@var string} using the "{@code %xx}"
escape. Letters, digits, and the characters "{@code _.-}" are never
quoted. The optional {@var safe} parameter specifies additional
characters that should not be quoted -- its default value is {@code
'/'}.

<p>Example: {@code quote('/~connolly/')} yields {@code '/%7econnolly/'}.

@@function quote_plus(string[, safe])

<p>Like {@link quote}, but also replaces spaces by plus signs, as
required for quoting HTML form values. Plus signs in the original string
are escaped unless they are included in {@var safe}. It also does not
have {@var safe} default to {@code '/'}.

@@function unquote(string)

<p>Replace "{@code %xx}" escapes by their single-character equivalent.

<p>Example: {@code unquote('/%7Econnolly/')} yields {@code
'/~connolly/'}.

@@function unquote_plus(string)

<p>Like {@link unquote}, but also replaces plus signs by spaces, as
required for unquoting HTML form values.

@@function urlencode(query[, doseq])

<p>Convert a mapping object or a sequence of two-element tuples to a
&#8220;url-encoded&#8221; string, suitable to pass to {@link urlopen}
above as the optional {@var data} argument. This is useful to pass a
dictionary of form fields to a {@code POST} request. The resulting
string is a series of {@code }{@var key}={@var value} pairs separated by
"{@code &amp;}" characters, where both {@var key} and {@var value} are
quoted using {@link quote_plus} above. If the optional parameter {@var
doseq} is present and evaluates to true, individual {@var key}={@var
value} pairs are generated for each element of the sequence. When a
sequence of two-element tuples is used as the {@var query} argument, the
first element of each tuple is a key and the second is a value. The
order of parameters in the encoded string will match the order of
parameter tuples in the sequence. The {@link cgi} module provides the
functions {@link parse_qs} and {@link parse_qsl} which are used to parse
query strings into Python data structures.

@@function pathname2url(path)

<p>Convert the pathname {@var path} from the local syntax for a path to
the form used in the path component of a URL. This does not produce a
complete URL. The return value will already be quoted using the {@link
quote} function.

@@function url2pathname(path)

<p>Convert the path component {@var path} from an encoded URL to the
local syntax for a path. This does not accept a complete URL. This
function uses {@link unquote} to decode {@var path}.

@@class URLopener([proxies[, **x509]])

<p>Base class for opening and reading URLs. Unless you need to support
opening objects using schemes other than http:, ftp:, gopher: or file:,
you probably want to use {@link FancyURLopener}.

<p>By default, the {@link URLopener} class sends a User-Agent: header of
"{@code urllib/}{@var VVV}", where {@var VVV} is the {@link urllib}
version number. Applications can define their own User-Agent: header by
subclassing {@link URLopener} or {@link FancyURLopener} and setting the
class attribute {@link version} to an appropriate string value in the
subclass definition.

<p>The optional {@var proxies} parameter should be a dictionary mapping
scheme names to proxy URLs, where an empty dictionary turns proxies off
completely. Its default value is {@link None}, in which case
environmental proxy settings will be used if present, as discussed in
the definition of {@link urlopen}, above.

<p>Additional keyword parameters, collected in {@var x509}, are used for
authentication with the https: scheme. The keywords {@var key_file} and
{@var cert_file} are supported; both are needed to actually retrieve a
resource at an https: URL.

@@class FancyURLopener(...)

<p>{@link FancyURLopener} subclasses {@link URLopener} providing default
handling for the following HTTP response codes: 301, 302, 303, 307 and
401. For the 30x response codes listed above, the Location: header is
used to fetch the actual URL. For 401 response codes (authentication
required), basic HTTP authentication is performed. For the 30x response
codes, recursion is bounded by the value of the {@var maxtries}
attribute, which defaults to 10.

<p class='note'><b>Note:</b> According to the letter of {@link
http://www.faqs.org/rfcs/rfc2616.html RFC 2616}, 301 and 302 responses
to POST requests must not be automatically redirected without
confirmation by the user. In reality, browsers do allow automatic
redirection of these responses, changing the POST to a GET, and {@link
urllib} reproduces this behaviour.

<p>The parameters to the constructor are the same as those for {@link
URLopener}.

<p class='note'><b>Note:</b> When performing basic authentication, a
{@link FancyURLopener} instance calls its {@link prompt_user_passwd}
method. The default implementation asks the users for the required
information on the controlling terminal. A subclass may override this
method to support more appropriate behavior if needed.

@@text 

<p>Restrictions:
<ul>
<li>
<p>Currently, only the following protocols are supported: HTTP,
(versions 0.9 and 1.0), Gopher (but not Gopher-+), FTP, and local files.
<li>
<p>The caching feature of {@link urlretrieve} has been disabled until I
find the time to hack proper processing of Expiration time headers.
<li>
<p>There should be a function to query whether a particular URL is in
the cache.
<li>
<p>For backward compatibility, if a URL appears to point to a local file
but the file can't be opened, the URL is re-interpreted using the FTP
protocol. This can sometimes cause confusing error messages.
<li>
<p>The {@link urlopen} and {@link urlretrieve} functions can cause
arbitrarily long delays while waiting for a network connection to be set
up. This means that it is difficult to build an interactive Web client
using these functions without using threads.
<li>
<p>The data returned by {@link urlopen} or {@link urlretrieve} is the
raw data returned by the server. This may be binary data (e.g. an
image), plain text or (for example) HTML. The HTTP protocol provides
type information in the reply header, which can be inspected by looking
at the Content-Type: header. For the Gopher protocol, type information
is encoded in the URL; there is currently no easy way to extract it. If
the returned data is HTML, you can use the module {@link htmllib} to
parse it.
<li>
<p>The code handling the FTP protocol cannot differentiate between a
file and a directory. This can lead to unexpected behavior when
attempting to read a URL that points to a file that is not accessible.
If the URL ends in a {@code /}, it is assumed to refer to a directory
and will be handled accordingly. But if an attempt to read a file leads
to a 550 error (meaning the URL cannot be found or is not accessible,
often for permission reasons), then the path is treated as a directory
in order to handle the case when a directory is specified by a URL but
the trailing {@code /} has been left off. This can cause misleading
results when you try to fetch a file whose read permissions make it
inaccessible; the FTP code will try to read it, fail with a 550 error,
and then perform a directory listing for the unreadable file. If
fine-grained control is needed, consider using the {@link ftplib}
module, subclassing {@link FancyURLOpener}, or changing {@var
_urlopener} to meet your needs.
<li>
<p>This module does not support the use of proxies which require
authentication. This may be implemented in the future.
<li>
<p>Although the {@link urllib} module contains (undocumented) routines
to parse and unparse URL strings, the recommended interface for URL
manipulation is in module {@link urlparse}.
</ul>

<h2>URLopener Objects</h2>

<p>{@link URLopener} and {@link FancyURLopener} objects have the
following attributes.

@@method URLopener.open(fullurl[, data])

<p>Open {@var fullurl} using the appropriate protocol. This method sets
up cache and proxy information, then calls the appropriate open method
with its input arguments. If the scheme is not recognized, {@link
open_unknown} is called. The {@var data} argument has the same meaning
as the {@var data} argument of {@link urlopen}.

@@method URLopener.open_unknown(fullurl[, data])

<p>Overridable interface to open unknown URL types.

@@method URLopener.retrieve(url[, filename[, reporthook[, data]]])

<p>Retrieves the contents of {@var url} and places it in {@var
filename}. The return value is a tuple consisting of a local filename
and either a {@link mimetools.Message} object containing the response
headers (for remote URLs) or {@code None} (for local URLs). The caller
must then open and read the contents of {@var filename}. If {@var
filename} is not given and the URL refers to a local file, the input
filename is returned. If the URL is non-local and {@var filename} is not
given, the filename is the output of {@link tempfile.mktemp} with a
suffix that matches the suffix of the last path component of the input
URL. If {@var reporthook} is given, it must be a function accepting
three numeric parameters. It will be called after each chunk of data is
read from the network. {@var reporthook} is ignored for local URLs.

<p>If the {@var url} uses the http: scheme identifier, the optional
{@var data} argument may be given to specify a {@code POST} request
(normally the request type is {@code GET}). The {@var data} argument
must in standard application/x-www-form-urlencoded format; see the
{@link urlencode} function below.

@@attribute URLopener.version

<p>Variable that specifies the user agent of the opener object. To get
{@link urllib} to tell servers that it is a particular user agent, set
this in a subclass as a class variable or in the constructor before
calling the base constructor.

@@text 

<p>The {@link FancyURLopener} class offers one additional method that
should be overloaded to provide the appropriate behavior:

@@method URLopener.prompt_user_passwd(host, realm)

<p>Return information needed to authenticate the user at the given host
in the specified security realm. The return value should be a tuple,
{@code (}{@var user}, {@var password}), which can be used for basic
authentication.

<p>The implementation prompts for this information on the terminal; an
application should override this method to use an appropriate
interaction model in the local environment.

@@text 

<h2>Examples</h2>

<p>Here is an example session that uses the "{@code GET}" method to
retrieve a URL containing parameters:

<pre>
&gt;&gt;&gt; import urllib
&gt;&gt;&gt; params = urllib.urlencode({'spam': 1, 'eggs': 2, 'bacon': 0})
&gt;&gt;&gt; f = urllib.urlopen("http://www.musi-cal.com/cgi-bin/query?%s" % params)
&gt;&gt;&gt; print f.read()
</pre>


<p>The following example uses the "{@code POST}" method instead:

<pre>
&gt;&gt;&gt; import urllib
&gt;&gt;&gt; params = urllib.urlencode({'spam': 1, 'eggs': 2, 'bacon': 0})
&gt;&gt;&gt; f = urllib.urlopen("http://www.musi-cal.com/cgi-bin/query", params)
&gt;&gt;&gt; print f.read()
</pre>


<p>The following example uses an explicitly specified HTTP proxy,
overriding environment settings:

<pre>
&gt;&gt;&gt; import urllib
&gt;&gt;&gt; proxies = {'http': 'http://proxy.example.com:8080/'}
&gt;&gt;&gt; opener = urllib.FancyURLopener(proxies)
&gt;&gt;&gt; f = opener.open("http://www.python.org")
&gt;&gt;&gt; f.read()
</pre>


<p>The following example uses no proxies at all, overriding environment
settings:

<pre>
&gt;&gt;&gt; import urllib
&gt;&gt;&gt; opener = urllib.FancyURLopener({})
&gt;&gt;&gt; f = opener.open("http://www.python.org/")
&gt;&gt;&gt; f.read()
</pre>

