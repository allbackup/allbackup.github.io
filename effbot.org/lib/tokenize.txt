
@@module tokenize

<h1>tokenize&#8212;Tokenizer for Python source</h1>

<p>The {@link tokenize} module provides a lexical scanner for Python
source code, implemented in Python. The scanner in this module returns
comments as tokens as well, making it useful for implementing
&#8220;pretty-printers,&#8221; including colorizers for on-screen
displays.

<p>The primary entry point is a generator:

@@function generate_tokens(readline)

<p>The {@link generate_tokens} generator requires one argment, {@var
readline}, which must be a callable object which provides the same
interface as the {@link readline} method of built-in file objects (see
section {@link bltin-file-objects.html#bltin-file-objects}). Each call
to the function should return one line of input as a string.

<p>The generator produces 5-tuples with these members: the token type;
the token string; a 2-tuple {@code (}{@var srow}, {@var scol}) of ints
specifying the row and column where the token begins in the source; a
2-tuple {@code (}{@var erow}, {@var ecol}) of ints specifying the row
and column where the token ends in the source; and the line on which the
token was found. The line passed is the {@em logical} line; continuation
lines are included.
<blockquote>
@since New in version
2.2. <br />
</blockquote>

@@text 

<p>An older entry point is retained for backward compatibility:

@@function tokenize(readline[, tokeneater])

<p>The {@link tokenize} function accepts two parameters: one
representing the input stream, and one providing an output mechanism for
{@link tokenize}.

<p>The first parameter, {@var readline}, must be a callable object which
provides the same interface as the {@link readline} method of built-in
file objects (see section {@link
bltin-file-objects.html#bltin-file-objects}). Each call to the function
should return one line of input as a string.

<p>The second parameter, {@var tokeneater}, must also be a callable
object. It is called once for each token, with five arguments,
corresponding to the tuples generated by {@link generate_tokens}.

@@text 

<p>All constants from the {@link token} module are also exported from
{@link tokenize}, as are two additional token type values that might be
passed to the {@var tokeneater} function by {@link tokenize}:

@@variable COMMENT

<p>Token value used to indicate a comment.

@@variable NL

<p>Token value used to indicate a non-terminating newline. The NEWLINE
token indicates the end of a logical line of Python code; NL tokens are
generated when a logical line of code is continued over multiple
physical lines.
